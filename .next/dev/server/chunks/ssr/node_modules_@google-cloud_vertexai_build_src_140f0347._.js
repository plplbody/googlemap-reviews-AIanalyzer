module.exports = [
"[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.CREDENTIAL_ERROR_MESSAGE = exports.USER_AGENT = exports.SYSTEM_ROLE = exports.MODEL_ROLE = exports.USER_ROLE = exports.COUNT_TOKENS_METHOD = exports.STREAMING_GENERATE_CONTENT_METHOD = exports.GENERATE_CONTENT_METHOD = void 0;
/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ exports.GENERATE_CONTENT_METHOD = 'generateContent';
exports.STREAMING_GENERATE_CONTENT_METHOD = 'streamGenerateContent';
exports.COUNT_TOKENS_METHOD = 'countTokens';
exports.USER_ROLE = 'user';
exports.MODEL_ROLE = 'model';
exports.SYSTEM_ROLE = 'system';
const USER_AGENT_PRODUCT = 'model-builder';
const CLIENT_LIBRARY_VERSION = '1.10.0'; // x-release-please-version
const CLIENT_LIBRARY_LANGUAGE = `grpc-node/${CLIENT_LIBRARY_VERSION}`;
exports.USER_AGENT = `${USER_AGENT_PRODUCT}/${CLIENT_LIBRARY_VERSION} ${CLIENT_LIBRARY_LANGUAGE}`;
exports.CREDENTIAL_ERROR_MESSAGE = '\nUnable to authenticate your request\
        \nDepending on your run time environment, you can get authentication by\
        \n- if in local instance or cloud shell: `!gcloud auth login`\
        \n- if in Colab:\
        \n    -`from google.colab import auth`\
        \n    -`auth.authenticate_user()`\
        \n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication'; //# sourceMappingURL=constants.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.constants = void 0;
exports.constants = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)"); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/util.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.formulateSystemInstructionIntoContent = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)");
function formulateSystemInstructionIntoContent(systemInstruction) {
    if (typeof systemInstruction === 'string') {
        return {
            role: util_1.constants.SYSTEM_ROLE,
            parts: [
                {
                    text: systemInstruction
                }
            ]
        };
    }
    systemInstruction.role = util_1.constants.SYSTEM_ROLE;
    return systemInstruction;
}
exports.formulateSystemInstructionIntoContent = formulateSystemInstructionIntoContent; //# sourceMappingURL=util.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.IllegalArgumentError = exports.GoogleGenerativeAIError = exports.GoogleAuthError = exports.GoogleApiError = exports.ClientError = void 0;
/**
 * GoogleAuthError is thrown when there is authentication issue with the request
 */ class GoogleAuthError extends Error {
    constructor(message, stackTrace){
        super(message, {
            cause: stackTrace
        });
        this.message = constructErrorMessage('GoogleAuthError', message);
        this.name = 'GoogleAuthError';
        this.stackTrace = stackTrace;
    }
}
exports.GoogleAuthError = GoogleAuthError;
/**
 * ClientError is thrown when http 4XX status is received.
 * For details please refer to https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses
 */ class ClientError extends Error {
    constructor(message, stackTrace){
        super(message, {
            cause: stackTrace
        });
        this.message = constructErrorMessage('ClientError', message);
        this.name = 'ClientError';
        this.stackTrace = stackTrace;
    }
}
exports.ClientError = ClientError;
/**
 * GoogleApiError is thrown when http 4XX status is received.
 * See https://cloud.google.com/apis/design/errors
 */ class GoogleApiError extends Error {
    constructor(message, code, status, errorDetails){
        super(message);
        this.code = code;
        this.status = status;
        this.errorDetails = errorDetails;
    }
}
exports.GoogleApiError = GoogleApiError;
/**
 * GoogleGenerativeAIError is thrown when http response is not ok and status code is not 4XX
 * For details please refer to https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
 */ class GoogleGenerativeAIError extends Error {
    constructor(message, stackTrace){
        super(message, {
            cause: stackTrace
        });
        this.message = constructErrorMessage('GoogleGenerativeAIError', message);
        this.name = 'GoogleGenerativeAIError';
        this.stackTrace = stackTrace;
    }
}
exports.GoogleGenerativeAIError = GoogleGenerativeAIError;
/**
 * IllegalArgumentError is thrown when the request or operation is invalid
 */ class IllegalArgumentError extends Error {
    constructor(message, stackTrace){
        super(message, {
            cause: stackTrace
        });
        this.message = constructErrorMessage('IllegalArgumentError', message);
        this.name = 'IllegalArgumentError';
        this.stackTrace = stackTrace;
    }
}
exports.IllegalArgumentError = IllegalArgumentError;
function constructErrorMessage(exceptionClass, message) {
    return `[VertexAI.${exceptionClass}]: ${message}`;
} //# sourceMappingURL=errors.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_fetch_processing.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.processCountTokenResponse = exports.processUnary = exports.aggregateResponses = exports.processStream = exports.throwErrorIfNotOK = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)");
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
async function throwErrorIfNotOK(response) {
    if (response === undefined) {
        throw new errors_1.GoogleGenerativeAIError('response is undefined');
    }
    if (!response.ok) {
        const status = response.status;
        const statusText = response.statusText;
        const errorBody = await response.json();
        const errorMessage = `got status: ${status} ${statusText}. ${JSON.stringify(errorBody)}`;
        if (status >= 400 && status < 500) {
            const error = new errors_1.ClientError(errorMessage, new errors_1.GoogleApiError(errorBody.error.message, errorBody.error.code, errorBody.error.status, errorBody.error.details));
            throw error;
        }
        throw new errors_1.GoogleGenerativeAIError(errorMessage);
    }
}
exports.throwErrorIfNotOK = throwErrorIfNotOK;
const responseLineRE = /^data: (.*)(?:\n\n|\r\r|\r\n\r\n)/;
async function* generateResponseSequence(stream) {
    const reader = stream.getReader();
    while(true){
        const { value, done } = await reader.read();
        if (done) {
            break;
        }
        yield addMissingIndexAndRole(value);
    }
}
/**
 * Process a response.body stream from the backend and return an
 * iterator that provides one complete GenerateContentResponse at a time
 * and a promise that resolves with a single aggregated
 * GenerateContentResponse.
 *
 * @param response - Response from a fetch call
 * @ignore
 */ async function processStream(response) {
    if (response === undefined) {
        throw new errors_1.GoogleGenerativeAIError('Error processing stream because response === undefined');
    }
    if (!response.body) {
        throw new errors_1.GoogleGenerativeAIError('Error processing stream because response.body not found');
    }
    const inputStream = response.body.pipeThrough(new TextDecoderStream('utf8', {
        fatal: true
    }));
    const responseStream = getResponseStream(inputStream);
    const [stream1, stream2] = responseStream.tee();
    return Promise.resolve({
        stream: generateResponseSequence(stream1),
        response: getResponsePromise(stream2)
    });
}
exports.processStream = processStream;
async function getResponsePromise(stream) {
    const allResponses = [];
    const reader = stream.getReader();
    // eslint-disable-next-line no-constant-condition
    while(true){
        const { done, value } = await reader.read();
        if (done) {
            return aggregateResponses(allResponses);
        }
        allResponses.push(value);
    }
}
/**
 * Reads a raw stream from the fetch response and join incomplete
 * chunks, returning a new stream that provides a single complete
 * GenerateContentResponse in each iteration.
 * @ignore
 */ function getResponseStream(inputStream) {
    const reader = inputStream.getReader();
    const stream = new ReadableStream({
        start (controller) {
            let currentText = '';
            return pump();
            //TURBOPACK unreachable
            ;
            function pump() {
                return reader.read().then(({ value, done })=>{
                    if (done) {
                        if (currentText.trim()) {
                            controller.error(new errors_1.GoogleGenerativeAIError(`Failed to parse final chunk of stream: ${currentText}`));
                            return;
                        }
                        controller.close();
                        return;
                    }
                    currentText += value;
                    let match = currentText.match(responseLineRE);
                    let parsedResponse;
                    while(match){
                        try {
                            parsedResponse = JSON.parse(match[1]);
                        } catch (e) {
                            controller.error(new errors_1.GoogleGenerativeAIError(`Error parsing JSON response from stream chunk: "${match[1]}"`));
                            return;
                        }
                        controller.enqueue(parsedResponse);
                        currentText = currentText.substring(match[0].length);
                        match = currentText.match(responseLineRE);
                    }
                    return pump();
                });
            }
        }
    });
    return stream;
}
/**
 * Aggregates an array of `GenerateContentResponse`s into a single
 * GenerateContentResponse.
 * @ignore
 * @VisibleForTesting
 */ function aggregateResponses(responses) {
    var _a, _b, _c, _d;
    const lastResponse = responses[responses.length - 1];
    if (lastResponse === undefined) {
        throw new errors_1.GoogleGenerativeAIError('Error aggregating stream chunks because the final response in stream chunk is undefined');
    }
    const aggregatedResponse = {};
    if (lastResponse.promptFeedback) {
        aggregatedResponse.promptFeedback = lastResponse.promptFeedback;
    }
    if (lastResponse.usageMetadata) {
        aggregatedResponse.usageMetadata = lastResponse.usageMetadata;
    }
    for (const response of responses){
        if (!response.candidates || response.candidates.length === 0) {
            continue;
        }
        for(let i = 0; i < response.candidates.length; i++){
            if (!aggregatedResponse.candidates) {
                aggregatedResponse.candidates = [];
            }
            if (!aggregatedResponse.candidates[i]) {
                aggregatedResponse.candidates[i] = {
                    index: (_a = response.candidates[i].index) !== null && _a !== void 0 ? _a : i,
                    content: {
                        role: (_c = (_b = response.candidates[i].content) === null || _b === void 0 ? void 0 : _b.role) !== null && _c !== void 0 ? _c : util_1.constants.MODEL_ROLE,
                        parts: [
                            {
                                text: ''
                            }
                        ]
                    }
                };
            }
            const citationMetadataAggregated = aggregateCitationMetadataForCandidate(response.candidates[i], aggregatedResponse.candidates[i]);
            if (citationMetadataAggregated) {
                aggregatedResponse.candidates[i].citationMetadata = citationMetadataAggregated;
            }
            const finishResonOfChunk = response.candidates[i].finishReason;
            if (finishResonOfChunk) {
                aggregatedResponse.candidates[i].finishReason = response.candidates[i].finishReason;
            }
            const finishMessageOfChunk = response.candidates[i].finishMessage;
            if (finishMessageOfChunk) {
                aggregatedResponse.candidates[i].finishMessage = finishMessageOfChunk;
            }
            const safetyRatingsOfChunk = response.candidates[i].safetyRatings;
            if (safetyRatingsOfChunk) {
                aggregatedResponse.candidates[i].safetyRatings = safetyRatingsOfChunk;
            }
            if (response.candidates[i].content && response.candidates[i].content.parts && response.candidates[i].content.parts.length > 0) {
                const { parts } = aggregatedResponse.candidates[i].content;
                for (const part of response.candidates[i].content.parts){
                    // NOTE: cannot have text and functionCall both in the same part.
                    // add functionCall(s) to new parts.
                    if (part.text) {
                        parts[0].text += part.text;
                    }
                    if (part.functionCall) {
                        parts.push({
                            functionCall: part.functionCall
                        });
                    }
                }
            }
            const groundingMetadataAggregated = aggregateGroundingMetadataForCandidate(response.candidates[i], aggregatedResponse.candidates[i]);
            if (groundingMetadataAggregated) {
                aggregatedResponse.candidates[i].groundingMetadata = groundingMetadataAggregated;
            }
        }
    }
    if ((_d = aggregatedResponse.candidates) === null || _d === void 0 ? void 0 : _d.length) {
        aggregatedResponse.candidates.forEach((candidate)=>{
            if (candidate.content.parts.length > 1 && candidate.content.parts[0].text === '') {
                candidate.content.parts.shift(); // remove empty text parameter
            }
        });
    }
    return aggregatedResponse;
}
exports.aggregateResponses = aggregateResponses;
function aggregateCitationMetadataForCandidate(candidateChunk, aggregatedCandidate) {
    var _a;
    if (!candidateChunk.citationMetadata) {
        return;
    }
    const emptyCitationMetadata = {
        citations: []
    };
    const citationMetadataAggregated = (_a = aggregatedCandidate.citationMetadata) !== null && _a !== void 0 ? _a : emptyCitationMetadata;
    const citationMetadataChunk = candidateChunk.citationMetadata;
    if (citationMetadataChunk.citations) {
        citationMetadataAggregated.citations = citationMetadataAggregated.citations.concat(citationMetadataChunk.citations);
    }
    return citationMetadataAggregated;
}
function aggregateGroundingMetadataForCandidate(candidateChunk, aggregatedCandidate) {
    var _a;
    if (!candidateChunk.groundingMetadata) {
        return;
    }
    const emptyGroundingMetadata = {
        webSearchQueries: [],
        retrievalQueries: [],
        groundingChunks: [],
        groundingSupports: []
    };
    const groundingMetadataAggregated = (_a = aggregatedCandidate.groundingMetadata) !== null && _a !== void 0 ? _a : emptyGroundingMetadata;
    const groundingMetadataChunk = candidateChunk.groundingMetadata;
    if (groundingMetadataChunk.webSearchQueries) {
        groundingMetadataAggregated.webSearchQueries = groundingMetadataAggregated.webSearchQueries.concat(groundingMetadataChunk.webSearchQueries);
    }
    if (groundingMetadataChunk.retrievalQueries) {
        groundingMetadataAggregated.retrievalQueries = groundingMetadataAggregated.retrievalQueries.concat(groundingMetadataChunk.retrievalQueries);
    }
    if (groundingMetadataChunk.groundingChunks) {
        groundingMetadataAggregated.groundingChunks = groundingMetadataAggregated.groundingChunks.concat(groundingMetadataChunk.groundingChunks);
    }
    if (groundingMetadataChunk.groundingSupports) {
        groundingMetadataAggregated.groundingSupports = groundingMetadataAggregated.groundingSupports.concat(groundingMetadataChunk.groundingSupports);
    }
    if (groundingMetadataChunk.searchEntryPoint) {
        groundingMetadataAggregated.searchEntryPoint = groundingMetadataChunk.searchEntryPoint;
    }
    return groundingMetadataAggregated;
}
function addMissingIndexAndRole(response) {
    const generateContentResponse = response;
    if (generateContentResponse.candidates && generateContentResponse.candidates.length > 0) {
        generateContentResponse.candidates.forEach((candidate, index)=>{
            if (candidate.index === undefined) {
                generateContentResponse.candidates[index].index = index;
            }
            if (candidate.content === undefined) {
                generateContentResponse.candidates[index].content = {};
            }
            if (candidate.content.role === undefined) {
                generateContentResponse.candidates[index].content.role = util_1.constants.MODEL_ROLE;
            }
        });
    }
    return generateContentResponse;
}
/**
 * Process model responses from generateContent
 * @ignore
 */ async function processUnary(response) {
    if (response !== undefined) {
        // ts-ignore
        const responseJson = await response.json();
        const generateContentResponse = addMissingIndexAndRole(responseJson);
        return Promise.resolve({
            response: generateContentResponse
        });
    }
    return Promise.resolve({
        response: {}
    });
}
exports.processUnary = processUnary;
/**
 * Process model responses from countTokens
 * @ignore
 */ async function processCountTokenResponse(response) {
    if (response) {
        // ts-ignore
        return response.json();
    }
    return Promise.resolve({});
}
exports.processCountTokenResponse = processCountTokenResponse; //# sourceMappingURL=post_fetch_processing.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_request.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.postRequest = void 0;
const API_BASE_PATH = 'aiplatform.googleapis.com';
const GOOGLE_INTERNAL_ENDPOINT = 'googleapis.com';
const AUTHORIZATION_HEADER = 'Authorization';
const CONTENT_TYPE_HEADER = 'Content-Type';
const USER_AGENT_HEADER = 'User-Agent';
const X_GOOG_API_CLIENT_HEADER = 'X-Goog-Api-Client';
const SERVER_RESERVED_HEADERS = [
    AUTHORIZATION_HEADER,
    CONTENT_TYPE_HEADER
];
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const constants = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)");
/**
 * Makes a POST request to a Vertex service
 * @ignore
 */ async function postRequest({ region, resourcePath, resourceMethod, token, data, apiEndpoint, requestOptions, apiVersion = 'v1' }) {
    const vertexBaseEndpoint = apiEndpoint !== null && apiEndpoint !== void 0 ? apiEndpoint : `${region}-${API_BASE_PATH}`;
    let vertexEndpoint = `https://${vertexBaseEndpoint}/${apiVersion}/${resourcePath}:${resourceMethod}`;
    // Use server sent events for streamGenerateContent
    if (resourceMethod === constants.STREAMING_GENERATE_CONTENT_METHOD) {
        vertexEndpoint += '?alt=sse';
    }
    const necessaryHeaders = new Headers({
        [AUTHORIZATION_HEADER]: `Bearer ${token}`,
        [CONTENT_TYPE_HEADER]: 'application/json',
        [USER_AGENT_HEADER]: constants.USER_AGENT
    });
    const totalHeaders = getExtraHeaders(vertexBaseEndpoint, necessaryHeaders, requestOptions);
    return fetch(vertexEndpoint, {
        ...getFetchOptions(requestOptions),
        method: 'POST',
        headers: totalHeaders,
        body: JSON.stringify(data)
    });
}
exports.postRequest = postRequest;
function getFetchOptions(requestOptions) {
    const fetchOptions = {};
    if (!requestOptions || requestOptions.timeout === undefined || requestOptions.timeout < 0) {
        return fetchOptions;
    }
    const abortController = new AbortController();
    const signal = abortController.signal;
    setTimeout(()=>abortController.abort(), requestOptions.timeout);
    fetchOptions.signal = signal;
    return fetchOptions;
}
function stringHasLineBreak(header) {
    if (header === null || header === undefined) {
        return false;
    }
    return header.includes('\n') || header.includes('\r');
}
function headersHasLineBreak(customHeaders) {
    if (!customHeaders) {
        return false;
    }
    for (const [key, value] of customHeaders.entries()){
        if (stringHasLineBreak(key) || stringHasLineBreak(value)) {
            return true;
        }
    }
    return false;
}
function getExtraHeaders(vertexBaseEndpoint, necessaryHeaders, requestOptions) {
    var _a;
    if (stringHasLineBreak(requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient)) {
        throw new errors_1.ClientError('Found line break in apiClient request option field, please remove ' + 'the line break and try again.');
    }
    if (headersHasLineBreak(requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.customHeaders)) {
        throw new errors_1.ClientError('Found line break in customerHeaders request option field, please remove ' + 'the line break and try again.');
    }
    const totalHeaders = new Headers(necessaryHeaders);
    const customHeaders = (_a = requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.customHeaders) !== null && _a !== void 0 ? _a : new Headers();
    for (const [key, val] of customHeaders.entries()){
        totalHeaders.append(key, val);
    }
    if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient) {
        totalHeaders.append(X_GOOG_API_CLIENT_HEADER, requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient);
    }
    // Resolve header conflicts.
    let goldenHeaders;
    if (vertexBaseEndpoint.endsWith(GOOGLE_INTERNAL_ENDPOINT)) {
        goldenHeaders = necessaryHeaders;
    } else {
        goldenHeaders = customHeaders;
    }
    for (const header of SERVER_RESERVED_HEADERS){
        if (goldenHeaders.has(header)) {
            totalHeaders.set(header, goldenHeaders.get(header));
        }
    }
    return totalHeaders;
} //# sourceMappingURL=post_request.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/pre_fetch_processing.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.hasVertexAISearch = exports.hasVertexRagStore = exports.getApiVersion = exports.validateGenerationConfig = exports.validateGenerateContentRequest = exports.formatContentRequest = void 0;
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const constants = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)");
function formatContentRequest(request, generationConfig, safetySettings) {
    if (typeof request === 'string') {
        return {
            contents: [
                {
                    role: constants.USER_ROLE,
                    parts: [
                        {
                            text: request
                        }
                    ]
                }
            ],
            generationConfig: generationConfig,
            safetySettings: safetySettings
        };
    } else {
        return request;
    }
}
exports.formatContentRequest = formatContentRequest;
function validateGenerateContentRequest(request) {
    if (hasVertexAISearch(request) && hasVertexRagStore(request)) {
        throw new errors_1.ClientError('Found both vertexAiSearch and vertexRagStore field are set in tool. Either set vertexAiSearch or vertexRagStore.');
    }
}
exports.validateGenerateContentRequest = validateGenerateContentRequest;
function validateGenerationConfig(generationConfig) {
    if ('topK' in generationConfig) {
        if (!(generationConfig.topK > 0) || !(generationConfig.topK <= 40)) {
            delete generationConfig.topK;
        }
    }
    return generationConfig;
}
exports.validateGenerationConfig = validateGenerationConfig;
function getApiVersion(request) {
    return hasVertexRagStore(request) || hasCachedContent(request) ? 'v1beta1' : 'v1';
}
exports.getApiVersion = getApiVersion;
function hasVertexRagStore(request) {
    var _a;
    for (const tool of (_a = request === null || request === void 0 ? void 0 : request.tools) !== null && _a !== void 0 ? _a : []){
        const retrieval = tool.retrieval;
        if (!retrieval) continue;
        if (retrieval.vertexRagStore) {
            return true;
        }
    }
    return false;
}
exports.hasVertexRagStore = hasVertexRagStore;
function hasCachedContent(request) {
    return !!request.cachedContent;
}
function hasVertexAISearch(request) {
    var _a;
    for (const tool of (_a = request === null || request === void 0 ? void 0 : request.tools) !== null && _a !== void 0 ? _a : []){
        const retrieval = tool.retrieval;
        if (!retrieval) continue;
        if (retrieval.vertexAiSearch) {
            return true;
        }
    }
    return false;
}
exports.hasVertexAISearch = hasVertexAISearch; //# sourceMappingURL=pre_fetch_processing.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/generate_content.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.generateContentStream = exports.generateContent = void 0;
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const constants = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)");
const post_fetch_processing_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_fetch_processing.js [app-rsc] (ecmascript)");
const post_request_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_request.js [app-rsc] (ecmascript)");
const pre_fetch_processing_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/pre_fetch_processing.js [app-rsc] (ecmascript)");
/**
 * Make a async call to generate content.
 * @param request A GenerateContentRequest object with the request contents.
 * @returns The GenerateContentResponse object with the response candidates.
 */ async function generateContent(location, resourcePath, token, request, apiEndpoint, generationConfig, safetySettings, tools, toolConfig, requestOptions) {
    var _a, _b, _c, _d;
    request = (0, pre_fetch_processing_1.formatContentRequest)(request, generationConfig, safetySettings);
    (0, pre_fetch_processing_1.validateGenerateContentRequest)(request);
    if (request.generationConfig) {
        request.generationConfig = (0, pre_fetch_processing_1.validateGenerationConfig)(request.generationConfig);
    }
    const generateContentRequest = {
        contents: request.contents,
        systemInstruction: request.systemInstruction,
        cachedContent: request.cachedContent,
        generationConfig: (_a = request.generationConfig) !== null && _a !== void 0 ? _a : generationConfig,
        safetySettings: (_b = request.safetySettings) !== null && _b !== void 0 ? _b : safetySettings,
        tools: (_c = request.tools) !== null && _c !== void 0 ? _c : tools,
        toolConfig: (_d = request.toolConfig) !== null && _d !== void 0 ? _d : toolConfig,
        labels: request.labels
    };
    const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath,
        resourceMethod: constants.GENERATE_CONTENT_METHOD,
        token: await token,
        data: generateContentRequest,
        apiEndpoint,
        requestOptions,
        apiVersion: (0, pre_fetch_processing_1.getApiVersion)(request)
    }).catch((e)=>{
        throw new errors_1.GoogleGenerativeAIError('exception posting request to model', e);
    });
    await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e)=>{
        throw e;
    });
    return (0, post_fetch_processing_1.processUnary)(response);
}
exports.generateContent = generateContent;
/**
 * Make an async stream request to generate content. The response will be
 * returned in stream.
 * @param {GenerateContentRequest} request - {@link GenerateContentRequest}
 * @returns {Promise<StreamGenerateContentResult>} Promise of {@link
 *     StreamGenerateContentResult}
 */ async function generateContentStream(location, resourcePath, token, request, apiEndpoint, generationConfig, safetySettings, tools, toolConfig, requestOptions) {
    var _a, _b, _c, _d;
    request = (0, pre_fetch_processing_1.formatContentRequest)(request, generationConfig, safetySettings);
    (0, pre_fetch_processing_1.validateGenerateContentRequest)(request);
    if (request.generationConfig) {
        request.generationConfig = (0, pre_fetch_processing_1.validateGenerationConfig)(request.generationConfig);
    }
    const generateContentRequest = {
        contents: request.contents,
        systemInstruction: request.systemInstruction,
        cachedContent: request.cachedContent,
        generationConfig: (_a = request.generationConfig) !== null && _a !== void 0 ? _a : generationConfig,
        safetySettings: (_b = request.safetySettings) !== null && _b !== void 0 ? _b : safetySettings,
        tools: (_c = request.tools) !== null && _c !== void 0 ? _c : tools,
        toolConfig: (_d = request.toolConfig) !== null && _d !== void 0 ? _d : toolConfig,
        labels: request.labels
    };
    const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath,
        resourceMethod: constants.STREAMING_GENERATE_CONTENT_METHOD,
        token: await token,
        data: generateContentRequest,
        apiEndpoint,
        requestOptions,
        apiVersion: (0, pre_fetch_processing_1.getApiVersion)(request)
    }).catch((e)=>{
        throw new errors_1.GoogleGenerativeAIError('exception posting request', e);
    });
    await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e)=>{
        throw e;
    });
    return (0, post_fetch_processing_1.processStream)(response);
}
exports.generateContentStream = generateContentStream; //# sourceMappingURL=generate_content.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/models/chat_session.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ChatSessionPreview = exports.ChatSession = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/util.js [app-rsc] (ecmascript)");
const generate_content_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/generate_content.js [app-rsc] (ecmascript)");
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const util_2 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)");
/**
 * The `ChatSession` class is used to make multiturn send message requests. You
 * can instantiate this class by using the `startChat` method in the
 * `GenerativeModel` class. The `sendMessage` method makes an async call to get
 * the response of a chat message at at once. The `sendMessageStream` method
 * makes an async call to stream the response of a chat message as it's being
 * generated.
 */ class ChatSession {
    async getHistory() {
        return Promise.resolve(this.historyInternal);
    }
    /**
     * @constructor
     * @param request - {@link StartChatSessionRequest}
     */ constructor(request, requestOptions){
        var _a;
        this.sendStreamPromise = Promise.resolve();
        this.project = request.project;
        this.location = request.location;
        this.googleAuth = request.googleAuth;
        this.resourcePath = request.resourcePath;
        this.historyInternal = (_a = request.history) !== null && _a !== void 0 ? _a : [];
        this.generationConfig = request.generationConfig;
        this.safetySettings = request.safetySettings;
        this.tools = request.tools;
        this.toolConfig = request.toolConfig;
        this.apiEndpoint = request.apiEndpoint;
        this.requestOptions = requestOptions !== null && requestOptions !== void 0 ? requestOptions : {};
        if (request.systemInstruction) {
            this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(request.systemInstruction);
        }
    }
    /**
     * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
     * fails.
     * @returns Promise of token.
     */ fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e)=>{
            throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
    }
    /**
     * Makes an async call to send chat message.
     *
     * The response is returned in {@link
     * GenerateContentResult.response}.
     *
     * @example
     * ```
     * const chat = generativeModel.startChat();
     * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
     * console.log('Response: ', JSON.stringify(result1.response));
     *
     * const result2 = await chat.sendMessage("What about python?");
     * console.log('Response: ', JSON.stringify(result2.response));
     * ```
     *
     * @param request - send message request.
     * @returns Promise of {@link GenerateContentResult}.
     */ async sendMessage(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
            contents: this.historyInternal.concat(newContent),
            safetySettings: this.safetySettings,
            generationConfig: this.generationConfig,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction
        };
        const generateContentResult = await (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e)=>{
            throw e;
        });
        const generateContentResponse = await generateContentResult.response;
        // Only push the latest message to history if the response returns a result
        if (generateContentResponse.candidates && generateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromModel = generateContentResponse.candidates[0].content;
            this.historyInternal.push(contentFromModel);
        }
        return Promise.resolve(generateContentResult);
    }
    async appendHistory(streamGenerateContentResultPromise, newContent) {
        const streamGenerateContentResult = await streamGenerateContentResultPromise;
        const streamGenerateContentResponse = await streamGenerateContentResult.response;
        // Only push the latest message to history if the response returned a result
        if (streamGenerateContentResponse.candidates && streamGenerateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromModel = streamGenerateContentResponse.candidates[0].content;
            this.historyInternal.push(contentFromModel);
        }
    }
    /**
     * Makes an async call to stream send message.
     *
     * The response is streamed chunk by chunk in
     * {@link StreamGenerateContentResult.stream}. The aggregated response is
     * avaliable in {@link StreamGenerateContentResult.response} after all chunks
     * are returned.
     *
     * @example
     * ```
     * const chat = generativeModel.startChat();
     * const chatInput = "How can I learn more about Node.js?";
     * const result = await chat.sendMessageStream(chatInput);
     * for await (const item of result.stream) {
     *   console.log(item.candidates[0].content.parts[0].text);
     * }
     * const response = await result.response;
     * console.log('aggregated response: ', JSON.stringify(result.response));
     * ```
     *
     * @param request - send message request.
     * @returns Promise of {@link StreamGenerateContentResult}.
     */ async sendMessageStream(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentrequest = {
            contents: this.historyInternal.concat(newContent),
            safetySettings: this.safetySettings,
            generationConfig: this.generationConfig,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction
        };
        const streamGenerateContentResultPromise = (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), generateContentrequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e)=>{
            throw e;
        });
        this.sendStreamPromise = this.appendHistory(streamGenerateContentResultPromise, newContent).catch((e)=>{
            // Errors from remote endpoint will be catchable by user from streamGenerateContentResultPromise
            // Errors in appendHistory should not throw to cause user's programe exit with code 1
            console.error(e);
        });
        return streamGenerateContentResultPromise;
    }
}
exports.ChatSession = ChatSession;
/**
 * The `ChatSessionPreview` class is used to make multiturn send message requests. You
 * can instantiate this class by using the `startChat` method in the
 * `GenerativeModelPreview` class. The `sendMessage` method makes an async call to get
 * the response of a chat message at at once. The `sendMessageStream` method
 * makes an async call to stream the response of a chat message as it's being
 * generated.
 */ class ChatSessionPreview {
    async getHistory() {
        return Promise.resolve(this.historyInternal);
    }
    /**
     * @constructor
     * @param request - {@link StartChatSessionRequest}
     */ constructor(request, requestOptions){
        var _a;
        this.sendStreamPromise = Promise.resolve();
        this.project = request.project;
        this.location = request.location;
        this.googleAuth = request.googleAuth;
        this.resourcePath = request.resourcePath;
        this.historyInternal = (_a = request.history) !== null && _a !== void 0 ? _a : [];
        this.generationConfig = request.generationConfig;
        this.safetySettings = request.safetySettings;
        this.tools = request.tools;
        this.toolConfig = request.toolConfig;
        this.apiEndpoint = request.apiEndpoint;
        this.requestOptions = requestOptions !== null && requestOptions !== void 0 ? requestOptions : {};
        this.cachedContent = request.cachedContent;
        if (request.systemInstruction) {
            this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(request.systemInstruction);
        }
    }
    /**
     * Gets access token from GoogleAuth. Throws GoogleAuthError when fails.
     * @returns Promise of token.
     */ fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e)=>{
            throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
    }
    /**
     * Makes an async call to send chat message.
     *
     * The response is returned in {@link
     * GenerateContentResult.response}.
     *
     * @example
     * ```
     * const chat = generativeModelPreview.startChat();
     * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
     * console.log('Response: ', JSON.stringify(result1.response));
     *
     * const result2 = await chat.sendMessage("What about python?");
     * console.log('Response: ', JSON.stringify(result2.response));
     * ```
     *
     * @param request - send message request.
     * @returns Promise of {@link GenerateContentResult}.
     */ async sendMessage(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
            contents: this.historyInternal.concat(newContent),
            safetySettings: this.safetySettings,
            generationConfig: this.generationConfig,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction,
            cachedContent: this.cachedContent
        };
        const generateContentResult = await (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e)=>{
            throw e;
        });
        const generateContentResponse = await generateContentResult.response;
        // Only push the latest message to history if the response returned a result
        if (generateContentResponse.candidates && generateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromAssistant = generateContentResponse.candidates[0].content;
            this.historyInternal.push(contentFromAssistant);
        }
        return Promise.resolve(generateContentResult);
    }
    async appendHistory(streamGenerateContentResultPromise, newContent) {
        const streamGenerateContentResult = await streamGenerateContentResultPromise;
        const streamGenerateContentResponse = await streamGenerateContentResult.response;
        // Only push the latest message to history if the response returned a result
        if (streamGenerateContentResponse.candidates && streamGenerateContentResponse.candidates.length !== 0) {
            this.historyInternal = this.historyInternal.concat(newContent);
            const contentFromAssistant = streamGenerateContentResponse.candidates[0].content;
            this.historyInternal.push(contentFromAssistant);
        }
    }
    /**
     * Makes an async call to stream send message.
     *
     * The response is streamed chunk by chunk in
     * {@link StreamGenerateContentResult.stream}. The aggregated response is
     * avaliable in {@link StreamGenerateContentResult.response} after all chunks
     * are returned.
     *
     * @example
     * ```
     * const chat = generativeModel.startChat();
     * const chatInput = "How can I learn more about Node.js?";
     * const result = await chat.sendMessageStream(chatInput);
     * for await (const item of result.stream) {
     *   console.log(item.candidates[0].content.parts[0].text);
     * }
     * const response = await result.response;
     * console.log('aggregated response: ', JSON.stringify(result.response));
     * ```
     *
     * @param request - send message request.
     * @returns Promise of {@link StreamGenerateContentResult}.
     */ async sendMessageStream(request) {
        const newContent = formulateNewContentFromSendMessageRequest(request);
        const generateContentRequest = {
            contents: this.historyInternal.concat(newContent),
            safetySettings: this.safetySettings,
            generationConfig: this.generationConfig,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction,
            cachedContent: this.cachedContent
        };
        const streamGenerateContentResultPromise = (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), generateContentRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions).catch((e)=>{
            throw e;
        });
        this.sendStreamPromise = this.appendHistory(streamGenerateContentResultPromise, newContent).catch((e)=>{
            // Errors from remote endpoint will be catchable by user from streamGenerateContentResultPromise
            // Errors in appendHistory should not throw to cause user's programe exit with code 1
            console.error(e);
        });
        return streamGenerateContentResultPromise;
    }
}
exports.ChatSessionPreview = ChatSessionPreview;
function formulateNewContentFromSendMessageRequest(request) {
    let newParts = [];
    if (typeof request === 'string') {
        newParts = [
            {
                text: request
            }
        ];
    } else if (Array.isArray(request)) {
        for (const item of request){
            if (typeof item === 'string') {
                newParts.push({
                    text: item
                });
            } else {
                newParts.push(item);
            }
        }
    }
    return assignRoleToPartsAndValidateSendMessageRequest(newParts);
}
/**
 * When multiple Part types (i.e. FunctionResponsePart and TextPart) are
 * passed in a single Part array, we may need to assign different roles to each
 * part. Currently only FunctionResponsePart requires a role other than 'user'.
 * @ignore
 * @param parts Array of parts to pass to the model
 * @returns Array of content items
 */ function assignRoleToPartsAndValidateSendMessageRequest(parts) {
    const userContent = {
        role: util_2.constants.USER_ROLE,
        parts: []
    };
    const functionContent = {
        role: util_2.constants.USER_ROLE,
        parts: []
    };
    let hasUserContent = false;
    let hasFunctionContent = false;
    for (const part of parts){
        if ('functionResponse' in part) {
            functionContent.parts.push(part);
            hasFunctionContent = true;
        } else {
            userContent.parts.push(part);
            hasUserContent = true;
        }
    }
    if (hasUserContent && hasFunctionContent) {
        throw new errors_1.ClientError('Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.');
    }
    if (!hasUserContent && !hasFunctionContent) {
        throw new errors_1.ClientError('No content is provided for sending chat message.');
    }
    if (hasUserContent) {
        return [
            userContent
        ];
    }
    return [
        functionContent
    ];
} //# sourceMappingURL=chat_session.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/functions/count_tokens.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.countTokens = void 0;
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const constants = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/constants.js [app-rsc] (ecmascript)");
const post_fetch_processing_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_fetch_processing.js [app-rsc] (ecmascript)");
const post_request_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/post_request.js [app-rsc] (ecmascript)");
/**
 * Make a async request to count tokens.
 * @param request A CountTokensRequest object with the request contents.
 * @returns The CountTokensResponse object with the token count.
 */ async function countTokens(location, resourcePath, token, request, apiEndpoint, requestOptions) {
    const response = await (0, post_request_1.postRequest)({
        region: location,
        resourcePath: resourcePath,
        resourceMethod: constants.COUNT_TOKENS_METHOD,
        token: await token,
        data: request,
        apiEndpoint: apiEndpoint,
        requestOptions: requestOptions
    }).catch((e)=>{
        throw new errors_1.GoogleGenerativeAIError('exception posting request', e);
    });
    await (0, post_fetch_processing_1.throwErrorIfNotOK)(response).catch((e)=>{
        throw e;
    });
    return (0, post_fetch_processing_1.processCountTokenResponse)(response);
}
exports.countTokens = countTokens; //# sourceMappingURL=count_tokens.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/models/generative_models.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.GenerativeModelPreview = exports.GenerativeModel = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/util.js [app-rsc] (ecmascript)");
const count_tokens_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/count_tokens.js [app-rsc] (ecmascript)");
const generate_content_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/generate_content.js [app-rsc] (ecmascript)");
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const util_2 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)");
const chat_session_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/models/chat_session.js [app-rsc] (ecmascript)");
/**
 * The `GenerativeModel` class is the base class for the generative models on
 * Vertex AI.
 * NOTE: Don't instantiate this class directly. Use
 * `vertexai.getGenerativeModel()` instead.
 */ class GenerativeModel {
    /**
     * @constructor
     * @param getGenerativeModelParams - {@link GetGenerativeModelParams}
     */ constructor(getGenerativeModelParams){
        var _a;
        this.project = getGenerativeModelParams.project;
        this.location = getGenerativeModelParams.location;
        this.apiEndpoint = getGenerativeModelParams.apiEndpoint;
        this.googleAuth = getGenerativeModelParams.googleAuth;
        this.model = getGenerativeModelParams.model;
        this.generationConfig = getGenerativeModelParams.generationConfig;
        this.safetySettings = getGenerativeModelParams.safetySettings;
        this.tools = getGenerativeModelParams.tools;
        this.toolConfig = getGenerativeModelParams.toolConfig;
        this.requestOptions = (_a = getGenerativeModelParams.requestOptions) !== null && _a !== void 0 ? _a : {};
        if (getGenerativeModelParams.systemInstruction) {
            this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(getGenerativeModelParams.systemInstruction);
        }
        this.resourcePath = formulateResourcePathFromModel(this.model, this.project, this.location);
        // publisherModelEndpoint is deprecated
        this.publisherModelEndpoint = this.resourcePath;
    }
    /**
     * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
     * fails.
     * @returns Promise of token string.
     */ fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e)=>{
            throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
    }
    /**
     * Makes an async call to generate content.
     *
     * The response will be returned in {@link
     * GenerateContentResult.response}.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const result = await generativeModel.generateContent(request);
     * console.log('Response: ', JSON.stringify(result.response));
     * ```
     *
     * @param request - A GenerateContentRequest object with the request contents.
     * @returns The GenerateContentResponse object with the response candidates.
     */ async generateContent(request) {
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction);
        return (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
    }
    /**
     * Makes an async stream request to generate content.
     *
     * The response is returned chunk by chunk as it's being generated in {@link
     * StreamGenerateContentResult.stream}. After all chunks of the response are
     * returned, the aggregated response is available in
     * {@link StreamGenerateContentResult.response}.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const streamingResult = await generativeModel.generateContentStream(request);
     * for await (const item of streamingResult.stream) {
     *   console.log('stream chunk: ', JSON.stringify(item));
     * }
     * const aggregatedResponse = await streamingResult.response;
     * console.log('aggregated response: ', JSON.stringify(aggregatedResponse));
     * ```
     *
     * @param request - {@link GenerateContentRequest}
     * @returns Promise of {@link StreamGenerateContentResult}
     */ async generateContentStream(request) {
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction);
        return (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
    }
    /**
     * Makes an async request to count tokens.
     *
     * The `countTokens` function returns the token count and the number of
     * billable characters for a prompt.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const resp = await generativeModel.countTokens(request);
     * console.log('count tokens response: ', resp);
     * ```
     *
     * @param request - A CountTokensRequest object with the request contents.
     * @returns The CountTokensResponse object with the token count.
     */ async countTokens(request) {
        return (0, count_tokens_1.countTokens)(this.location, this.resourcePath, this.fetchToken(), request, this.apiEndpoint, this.requestOptions);
    }
    /**
     * Instantiates a {@link ChatSession}.
     *
     * The {@link ChatSession} class is a stateful class that holds the state of
     * the conversation with the model and provides methods to interact with the
     * model in chat mode. Calling this method doesn't make any calls to a remote
     * endpoint. To make remote call, use {@link ChatSession.sendMessage} or
     * @link ChatSession.sendMessageStream}.
     *
     * @example
     * ```
     * const chat = generativeModel.startChat();
     * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
     * const response1 = await result1.response;
     * console.log('Response: ', JSON.stringify(response1));
     *
     * const result2 = await chat.sendMessageStream("What about python?");
     * const response2 = await result2.response;
     * console.log('Response: ', JSON.stringify(await response2));
     * ```
     *
     * @param request - {@link StartChatParams}
     * @returns {@link ChatSession}
     */ startChat(request) {
        var _a, _b, _c, _d, _e, _f;
        const startChatRequest = {
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            publisherModelEndpoint: this.publisherModelEndpoint,
            resourcePath: this.resourcePath,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction
        };
        if (request) {
            startChatRequest.history = request.history;
            startChatRequest.generationConfig = (_a = request.generationConfig) !== null && _a !== void 0 ? _a : this.generationConfig;
            startChatRequest.safetySettings = (_b = request.safetySettings) !== null && _b !== void 0 ? _b : this.safetySettings;
            startChatRequest.tools = (_c = request.tools) !== null && _c !== void 0 ? _c : this.tools;
            startChatRequest.toolConfig = (_d = request.toolConfig) !== null && _d !== void 0 ? _d : this.toolConfig;
            startChatRequest.apiEndpoint = (_e = request.apiEndpoint) !== null && _e !== void 0 ? _e : this.apiEndpoint;
            startChatRequest.systemInstruction = (_f = request.systemInstruction) !== null && _f !== void 0 ? _f : this.systemInstruction;
        }
        return new chat_session_1.ChatSession(startChatRequest, this.requestOptions);
    }
}
exports.GenerativeModel = GenerativeModel;
/**
 * The `GenerativeModelPreview` class is the base class for the generative models
 * that are in preview.
 * NOTE: Don't instantiate this class directly. Use
 * `vertexai.preview.getGenerativeModel()` instead.
 */ class GenerativeModelPreview {
    /**
     * @constructor
     * @param getGenerativeModelParams - {@link GetGenerativeModelParams}
     */ constructor(getGenerativeModelParams){
        var _a;
        this.project = getGenerativeModelParams.project;
        this.location = getGenerativeModelParams.location;
        this.apiEndpoint = getGenerativeModelParams.apiEndpoint;
        this.googleAuth = getGenerativeModelParams.googleAuth;
        this.model = getGenerativeModelParams.model;
        this.generationConfig = getGenerativeModelParams.generationConfig;
        this.safetySettings = getGenerativeModelParams.safetySettings;
        this.tools = getGenerativeModelParams.tools;
        this.toolConfig = getGenerativeModelParams.toolConfig;
        this.cachedContent = getGenerativeModelParams.cachedContent;
        this.requestOptions = (_a = getGenerativeModelParams.requestOptions) !== null && _a !== void 0 ? _a : {};
        if (getGenerativeModelParams.systemInstruction) {
            this.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(getGenerativeModelParams.systemInstruction);
        }
        this.resourcePath = formulateResourcePathFromModel(this.model, this.project, this.location);
        // publisherModelEndpoint is deprecated
        this.publisherModelEndpoint = this.resourcePath;
    }
    /**
     * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
     * fails.
     * @returns Promise of token string.
     */ fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e)=>{
            throw new errors_1.GoogleAuthError(util_2.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
    }
    /**
     * Makes an async call to generate content.
     *
     * The response will be returned in {@link GenerateContentResult.response}.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const result = await generativeModelPreview.generateContent(request);
     * console.log('Response: ', JSON.stringify(result.response));
     * ```
     *
     * @param request - A GenerateContentRequest object with the request contents.
     * @returns The GenerateContentResponse object with the response candidates.
     */ async generateContent(request) {
        var _a;
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = {
            ...formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction),
            cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        return (0, generate_content_1.generateContent)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
    }
    /**
     * Makes an async stream request to generate content.
     *
     * The response is returned chunk by chunk as it's being generated in {@link
     * StreamGenerateContentResult.stream}. After all chunks of the response are
     * returned, the aggregated response is available in
     * {@link StreamGenerateContentResult.response}.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const streamingResult = await generativeModelPreview.generateContentStream(request);
     * for await (const item of streamingResult.stream) {
     *   console.log('stream chunk: ', JSON.stringify(item));
     * }
     * const aggregatedResponse = await streamingResult.response;
     * console.log('aggregated response: ', JSON.stringify(aggregatedResponse));
     * ```
     *
     * @param request - {@link GenerateContentRequest}
     * @returns Promise of {@link StreamGenerateContentResult}
     */ async generateContentStream(request) {
        var _a;
        request = formulateRequestToGenerateContentRequest(request);
        const formulatedRequest = {
            ...formulateSystemInstructionIntoGenerateContentRequest(request, this.systemInstruction),
            cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        return (0, generate_content_1.generateContentStream)(this.location, this.resourcePath, this.fetchToken(), formulatedRequest, this.apiEndpoint, this.generationConfig, this.safetySettings, this.tools, this.toolConfig, this.requestOptions);
    }
    /**
     * Makes an async request to count tokens.
     *
     * The `countTokens` function returns the token count and the number of
     * billable characters for a prompt.
     *
     * @example
     * ```
     * const request = {
     *   contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],
     * };
     * const resp = await generativeModelPreview.countTokens(request);
     * console.log('count tokens response: ', resp);
     * ```
     *
     * @param request - A CountTokensRequest object with the request contents.
     * @returns The CountTokensResponse object with the token count.
     */ async countTokens(request) {
        return (0, count_tokens_1.countTokens)(this.location, this.resourcePath, this.fetchToken(), request, this.apiEndpoint, this.requestOptions);
    }
    /**
     * Instantiates a {@link ChatSessionPreview}.
     *
     * The {@link ChatSessionPreview} class is a stateful class that holds the state of
     * the conversation with the model and provides methods to interact with the
     * model in chat mode. Calling this method doesn't make any calls to a remote
     * endpoint. To make remote call, use {@link ChatSessionPreview.sendMessage} or
     * {@link ChatSessionPreview.sendMessageStream}.
     *
     * @example
     * ```
     * const chat = generativeModelPreview.startChat();
     * const result1 = await chat.sendMessage("How can I learn more about Node.js?");
     * const response1 = await result1.response;
     * console.log('Response: ', JSON.stringify(response1));
     *
     * const result2 = await chat.sendMessageStream("What about python?");
     * const response2 = await result2.response;
     * console.log('Response: ', JSON.stringify(await response2));
     * ```
     *
     * @param request - {@link StartChatParams}
     * @returns {@link ChatSessionPreview}
     */ startChat(request) {
        var _a, _b, _c, _d, _e, _f, _g, _h;
        const startChatRequest = {
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            publisherModelEndpoint: this.publisherModelEndpoint,
            resourcePath: this.resourcePath,
            tools: this.tools,
            toolConfig: this.toolConfig,
            systemInstruction: this.systemInstruction,
            cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name
        };
        if (request) {
            startChatRequest.history = request.history;
            startChatRequest.generationConfig = (_b = request.generationConfig) !== null && _b !== void 0 ? _b : this.generationConfig;
            startChatRequest.safetySettings = (_c = request.safetySettings) !== null && _c !== void 0 ? _c : this.safetySettings;
            startChatRequest.tools = (_d = request.tools) !== null && _d !== void 0 ? _d : this.tools;
            startChatRequest.toolConfig = (_e = request.toolConfig) !== null && _e !== void 0 ? _e : this.toolConfig;
            startChatRequest.systemInstruction = (_f = request.systemInstruction) !== null && _f !== void 0 ? _f : this.systemInstruction;
            startChatRequest.cachedContent = (_g = request.cachedContent) !== null && _g !== void 0 ? _g : (_h = this.cachedContent) === null || _h === void 0 ? void 0 : _h.name;
        }
        return new chat_session_1.ChatSessionPreview(startChatRequest, this.requestOptions);
    }
    getModelName() {
        return this.model;
    }
    getCachedContent() {
        return this.cachedContent;
    }
    getSystemInstruction() {
        return this.systemInstruction;
    }
}
exports.GenerativeModelPreview = GenerativeModelPreview;
function formulateResourcePathFromModel(model, project, location) {
    let resourcePath;
    if (!model) {
        throw new errors_1.ClientError('model parameter must not be empty.');
    }
    if (!model.includes('/')) {
        // example 'gemini-1.0-pro'
        resourcePath = `projects/${project}/locations/${location}/publishers/google/models/${model}`;
    } else if (model.startsWith('models/')) {
        // example 'models/gemini-1.0-pro'
        resourcePath = `projects/${project}/locations/${location}/publishers/google/${model}`;
    } else if (model.startsWith('projects/')) {
        // example 'projects/my-project/locations/my-location/models/my-tuned-model'
        resourcePath = model;
    } else {
        throw new errors_1.ClientError('model parameter must be either a Model Garden model ID or a full resource name.');
    }
    return resourcePath;
}
function formulateRequestToGenerateContentRequest(request) {
    if (typeof request === 'string') {
        return {
            contents: [
                {
                    role: util_2.constants.USER_ROLE,
                    parts: [
                        {
                            text: request
                        }
                    ]
                }
            ]
        };
    }
    return request;
}
function formulateSystemInstructionIntoGenerateContentRequest(methodRequest, classSystemInstruction) {
    if (methodRequest.systemInstruction) {
        methodRequest.systemInstruction = (0, util_1.formulateSystemInstructionIntoContent)(methodRequest.systemInstruction);
        return methodRequest;
    }
    if (classSystemInstruction) {
        methodRequest.systemInstruction = classSystemInstruction;
    }
    return methodRequest;
} //# sourceMappingURL=generative_models.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/models/index.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.GenerativeModelPreview = exports.GenerativeModel = exports.ChatSessionPreview = exports.ChatSession = void 0;
var chat_session_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/models/chat_session.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "ChatSession", {
    enumerable: true,
    get: function() {
        return chat_session_1.ChatSession;
    }
});
Object.defineProperty(exports, "ChatSessionPreview", {
    enumerable: true,
    get: function() {
        return chat_session_1.ChatSessionPreview;
    }
});
var generative_models_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/models/generative_models.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "GenerativeModel", {
    enumerable: true,
    get: function() {
        return generative_models_1.GenerativeModel;
    }
});
Object.defineProperty(exports, "GenerativeModelPreview", {
    enumerable: true,
    get: function() {
        return generative_models_1.GenerativeModelPreview;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/common.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.SchemaType = void 0;
/** This file contains interfaces that are usable in the types folder. */ /**
 * The list of OpenAPI data types
 * as defined by https://swagger.io/docs/specification/data-models/data-types/
 */ var SchemaType;
(function(SchemaType) {
    /** String type. */ SchemaType["STRING"] = "STRING";
    /** Number type. */ SchemaType["NUMBER"] = "NUMBER";
    /** Integer type. */ SchemaType["INTEGER"] = "INTEGER";
    /** Boolean type. */ SchemaType["BOOLEAN"] = "BOOLEAN";
    /** Array type. */ SchemaType["ARRAY"] = "ARRAY";
    /** Object type. */ SchemaType["OBJECT"] = "OBJECT";
})(SchemaType || (exports.SchemaType = SchemaType = {})); //# sourceMappingURL=common.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/content.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.FunctionDeclarationSchemaType = exports.Mode = exports.FinishReason = exports.BlockedReason = exports.HarmSeverity = exports.HarmProbability = exports.HarmBlockThreshold = exports.HarmCategory = void 0;
const common_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/common.js [app-rsc] (ecmascript)");
/**
 * Harm categories that will block the content.
 */ var HarmCategory;
(function(HarmCategory) {
    /** The harm category is unspecified. */ HarmCategory["HARM_CATEGORY_UNSPECIFIED"] = "HARM_CATEGORY_UNSPECIFIED";
    /** The harm category is hate speech. */ HarmCategory["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
    /** The harm category is dangerous content. */ HarmCategory["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
    /** The harm category is harassment. */ HarmCategory["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
    /** The harm category is sexually explicit content. */ HarmCategory["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
})(HarmCategory || (exports.HarmCategory = HarmCategory = {}));
/**
 * Probability based thresholds levels for blocking.
 */ var HarmBlockThreshold;
(function(HarmBlockThreshold) {
    /** Unspecified harm block threshold. */ HarmBlockThreshold["HARM_BLOCK_THRESHOLD_UNSPECIFIED"] = "HARM_BLOCK_THRESHOLD_UNSPECIFIED";
    /** Block low threshold and above (i.e. block more). */ HarmBlockThreshold["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
    /** Block medium threshold and above. */ HarmBlockThreshold["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
    /** Block only high threshold (i.e. block less). */ HarmBlockThreshold["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
    /** Block none. */ HarmBlockThreshold["BLOCK_NONE"] = "BLOCK_NONE";
    /** Turn off the safety filter. */ HarmBlockThreshold["OFF"] = "OFF";
})(HarmBlockThreshold || (exports.HarmBlockThreshold = HarmBlockThreshold = {}));
/**
 * Harm probability levels in the content.
 */ var HarmProbability;
(function(HarmProbability) {
    /** Harm probability unspecified. */ HarmProbability["HARM_PROBABILITY_UNSPECIFIED"] = "HARM_PROBABILITY_UNSPECIFIED";
    HarmProbability["NEGLIGIBLE"] = "NEGLIGIBLE";
    /** Low level of harm. */ HarmProbability["LOW"] = "LOW";
    /** Medium level of harm. */ HarmProbability["MEDIUM"] = "MEDIUM";
    /** High level of harm. */ HarmProbability["HIGH"] = "HIGH";
})(HarmProbability || (exports.HarmProbability = HarmProbability = {}));
/**
 * Harm severity levels
 */ var HarmSeverity;
(function(HarmSeverity) {
    /** Harm severity unspecified. */ HarmSeverity["HARM_SEVERITY_UNSPECIFIED"] = "HARM_SEVERITY_UNSPECIFIED";
    /** Negligible level of harm severity. */ HarmSeverity["HARM_SEVERITY_NEGLIGIBLE"] = "HARM_SEVERITY_NEGLIGIBLE";
    /** Low level of harm severity. */ HarmSeverity["HARM_SEVERITY_LOW"] = "HARM_SEVERITY_LOW";
    /** Medium level of harm severity. */ HarmSeverity["HARM_SEVERITY_MEDIUM"] = "HARM_SEVERITY_MEDIUM";
    /** High level of harm severity. */ HarmSeverity["HARM_SEVERITY_HIGH"] = "HARM_SEVERITY_HIGH";
})(HarmSeverity || (exports.HarmSeverity = HarmSeverity = {}));
/**
 * The reason why the reponse is blocked.
 */ var BlockedReason;
(function(BlockedReason) {
    /** Unspecified blocked reason. */ BlockedReason["BLOCKED_REASON_UNSPECIFIED"] = "BLOCK_REASON_UNSPECIFIED";
    /** Candidates blocked due to safety. */ BlockedReason["SAFETY"] = "SAFETY";
    /** Candidates blocked due to other reason. */ BlockedReason["OTHER"] = "OTHER";
    /** terminology blocklist. */ BlockedReason["BLOCKLIST"] = "BLOCKLIST";
    /** Candidates blocked due to prohibited content. */ BlockedReason["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
})(BlockedReason || (exports.BlockedReason = BlockedReason = {}));
/**
 * The reason why the model stopped generating tokens.
 * If empty, the model has not stopped generating the tokens.
 */ var FinishReason;
(function(FinishReason) {
    /** The finish reason is unspecified. */ FinishReason["FINISH_REASON_UNSPECIFIED"] = "FINISH_REASON_UNSPECIFIED";
    /** Natural stop point of the model or provided stop sequence. */ FinishReason["STOP"] = "STOP";
    /** The maximum number of tokens as specified in the request was reached. */ FinishReason["MAX_TOKENS"] = "MAX_TOKENS";
    /**
     * The token generation was stopped as the response was flagged for safety
     * reasons.
     */ FinishReason["SAFETY"] = "SAFETY";
    /**
     * The token generation was stopped as the response was flagged for
     * unauthorized citations.
     */ FinishReason["RECITATION"] = "RECITATION";
    /** All other reasons that stopped the token generation. */ FinishReason["OTHER"] = "OTHER";
    /**
     * The token generation was stopped as the response was flagged for the
     * terms which are included from the terminology blocklist.
     */ FinishReason["BLOCKLIST"] = "BLOCKLIST";
    /**
     * The token generation was stopped as the response was flagged for
     * the prohibited contents.
     */ FinishReason["PROHIBITED_CONTENT"] = "PROHIBITED_CONTENT";
    /**
     * The token generation was stopped as the response was flagged for
     * Sensitive Personally Identifiable Information (SPII) contents.
     */ FinishReason["SPII"] = "SPII";
})(FinishReason || (exports.FinishReason = FinishReason = {}));
var Mode;
(function(Mode) {
    Mode["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
    Mode["MODE_DYNAMIC"] = "MODE_DYNAMIC";
})(Mode || (exports.Mode = Mode = {}));
exports.FunctionDeclarationSchemaType = {
    ...common_1.SchemaType
}; //# sourceMappingURL=content.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/tool.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.FunctionCallingMode = void 0;
/** Function calling mode. */ var FunctionCallingMode;
(function(FunctionCallingMode) {
    /** Unspecified function calling mode. This value should not be used. */ FunctionCallingMode["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
    /**
     * Default model behavior, model decides to predict either function calls
     * or natural language response.
     */ FunctionCallingMode["AUTO"] = "AUTO";
    /**
     * Model is constrained to always predicting function calls only.
     * If "allowedFunctionNames" are set, the predicted function calls will be
     * limited to any one of "allowedFunctionNames", else the predicted
     * function calls will be any one of the provided "function_declarations".
     */ FunctionCallingMode["ANY"] = "ANY";
    /**
     * Model will not predict any function calls. Model behavior is same as when
     * not passing any function declarations.
     */ FunctionCallingMode["NONE"] = "NONE";
})(FunctionCallingMode || (exports.FunctionCallingMode = FunctionCallingMode = {})); //# sourceMappingURL=tool.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/generate_content_response_handler.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.GenerateContentResponseHandler = void 0;
/** Helper class to render any extra properties out of
 * {@link GenerateContentResponse} or properties of {@link GenerateContentResponse}
 */ class GenerateContentResponseHandler {
    /**
     * Extracts function calls from a {@link GenerateContentCandidate}.
     *
     * @param candidate - The candidate to extract function calls from.
     * @returns the array of function calls in a {@link GenerateContentCandidate}.
     */ static getFunctionCallsFromCandidate(candidate) {
        if (!candidate) return [];
        return candidate.content.parts.filter((part)=>!!part && !!part.functionCall).map((part)=>part.functionCall);
    }
}
exports.GenerateContentResponseHandler = GenerateContentResponseHandler; //# sourceMappingURL=generate_content_response_handler.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/types/index.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ var __createBinding = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = {
            enumerable: true,
            get: function() {
                return m[k];
            }
        };
    }
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
});
var __exportStar = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__exportStar || function(m, exports1) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports1, p)) __createBinding(exports1, m, p);
};
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.GenerateContentResponseHandler = void 0;
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/content.js [app-rsc] (ecmascript)"), exports);
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)"), exports);
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/tool.js [app-rsc] (ecmascript)"), exports);
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/common.js [app-rsc] (ecmascript)"), exports);
var generate_content_response_handler_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/generate_content_response_handler.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "GenerateContentResponseHandler", {
    enumerable: true,
    get: function() {
        return generate_content_response_handler_1.GenerateContentResponseHandler;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/resources/cached_contents.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.CachedContents = exports.inferModelName = exports.inferFullResourceName = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/functions/util.js [app-rsc] (ecmascript)");
const types_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/index.js [app-rsc] (ecmascript)");
function camelToSnake(str) {
    return str.replace(/[A-Z]/g, (letter)=>`_${letter.toLowerCase()}`);
}
class CachedContentsClient {
    constructor(apiClient){
        this.apiClient = apiClient;
    }
    create(cachedContent) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + '/' + this.apiClient.getBaseResourePath() + '/cachedContents'), {
            body: JSON.stringify(cachedContent)
        }, 'POST');
    }
    update(cachedContent, updateMask) {
        const url = new URL(this.apiClient.getBaseUrl() + '/' + cachedContent.name);
        url.searchParams.append('updateMask', updateMask.map((e)=>camelToSnake(e)).join(','));
        return this.apiClient.unaryApiCall(url, {
            body: JSON.stringify(cachedContent)
        }, 'PATCH');
    }
    delete(name) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + '/' + name), {}, 'DELETE');
    }
    list(pageSize, pageToken) {
        const url = new URL(this.apiClient.getBaseUrl() + '/' + this.apiClient.getBaseResourePath() + '/cachedContents');
        if (pageSize) url.searchParams.append('pageSize', String(pageSize));
        if (pageToken) url.searchParams.append('pageToken', pageToken);
        return this.apiClient.unaryApiCall(url, {}, 'GET');
    }
    get(name) {
        return this.apiClient.unaryApiCall(new URL(this.apiClient.getBaseUrl() + '/' + name), {}, 'GET');
    }
}
function inferFullResourceName(project, location, cachedContentId) {
    if (cachedContentId.startsWith('projects/')) {
        return cachedContentId;
    }
    if (cachedContentId.startsWith('locations/')) {
        return `projects/${project}/${cachedContentId}`;
    }
    if (cachedContentId.startsWith('cachedContents/')) {
        return `projects/${project}/locations/${location}/${cachedContentId}`;
    }
    if (!cachedContentId.includes('/')) {
        return `projects/${project}/locations/${location}/cachedContents/${cachedContentId}`;
    }
    throw new types_1.ClientError(`Invalid CachedContent.name: ${cachedContentId}. CachedContent.name should start with 'projects/', 'locations/', 'cachedContents/' or is a number type.`);
}
exports.inferFullResourceName = inferFullResourceName;
/**
 * Infers the full model name based on the provided project, location, and model.
 *
 * @internal
 */ function inferModelName(project, location, model) {
    if (!model) {
        throw new types_1.ClientError('Model name is required.');
    }
    if (model.startsWith('publishers/')) {
        return `projects/${project}/locations/${location}/${model}`;
    }
    if (!model.startsWith('projects/')) {
        return `projects/${project}/locations/${location}/publishers/google/models/${model}`;
    }
    return model;
}
exports.inferModelName = inferModelName;
/**
 * This class is for managing Vertex AI's CachedContent resource.
 * @public
 */ class CachedContents {
    constructor(client){
        this.client = new CachedContentsClient(client);
    }
    /**
     * Creates cached content, this call will initialize the cached content in the data storage, and users need to pay for the cache data storage.
     * @param cachedContent
     * @param parent - Required. The parent resource where the cached content will be created.
     */ create(cachedContent) {
        const curatedCachedContent = {
            ...cachedContent,
            systemInstruction: cachedContent.systemInstruction ? (0, util_1.formulateSystemInstructionIntoContent)(cachedContent.systemInstruction) : undefined,
            model: inferModelName(this.client.apiClient.project, this.client.apiClient.location, cachedContent.model)
        };
        return this.client.create(curatedCachedContent);
    }
    /**
     * Updates cached content configurations
     *
     * @param updateMask - Required. The list of fields to update. Format: google-fieldmask. See {@link https://cloud.google.com/docs/discovery/type-format}
     * @param name - Immutable. Identifier. The server-generated resource name of the cached content Format: projects/{project}/locations/{location}/cachedContents/{cached_content}.
     */ update(cachedContent, updateMask) {
        if (!cachedContent.name) {
            throw new types_1.ClientError('Cached content name is required for update.');
        }
        if (!updateMask || updateMask.length === 0) {
            throw new types_1.ClientError('Update mask is required for update. Fields set in cachedContent but not in updateMask will be ignored. Examples: ["ttl"] or ["expireTime"].');
        }
        const curatedCachedContent = {
            ...cachedContent,
            systemInstruction: cachedContent.systemInstruction ? (0, util_1.formulateSystemInstructionIntoContent)(cachedContent.systemInstruction) : undefined,
            name: inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, cachedContent.name)
        };
        return this.client.update(curatedCachedContent, updateMask);
    }
    /**
     * Deletes cached content.
     *
     * @param name - Required. The resource name referring to the cached content.
     */ delete(name) {
        return this.client.delete(inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, name));
    }
    /**
     * Lists cached contents in a project.
     *
     * @param pageSize - Optional. The maximum number of cached contents to return. The service may return fewer than this value. If unspecified, some default (under maximum) number of items will be returned. The maximum value is 1000; values above 1000 will be coerced to 1000.
     * @param pageToken - Optional. A page token, received from a previous `ListCachedContents` call. Provide this to retrieve the subsequent page. When paginating, all other parameters provided to `ListCachedContents` must match the call that provided the page token.
     */ list(pageSize, pageToken) {
        return this.client.list(pageSize, pageToken);
    }
    /**
     * Gets cached content configurations.
     *
     * @param name - Required. The resource name referring to the cached content.
     */ get(name) {
        return this.client.get(inferFullResourceName(this.client.apiClient.project, this.client.apiClient.location, name));
    }
}
exports.CachedContents = CachedContents; //# sourceMappingURL=cached_contents.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/resources/shared/api_client.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ApiClient = void 0;
const util_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/util/index.js [app-rsc] (ecmascript)");
const types_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/index.js [app-rsc] (ecmascript)");
const AUTHORIZATION_HEADER = 'Authorization';
const CONTENT_TYPE_HEADER = 'Content-Type';
const USER_AGENT_HEADER = 'User-Agent';
class ApiClient {
    constructor(project, location, apiVersion, googleAuth){
        this.project = project;
        this.location = location;
        this.apiVersion = apiVersion;
        this.googleAuth = googleAuth;
    }
    /**
     * Gets access token from GoogleAuth. Throws {@link GoogleAuthError} when
     * fails.
     * @returns Promise of token string.
     */ fetchToken() {
        const tokenPromise = this.googleAuth.getAccessToken().catch((e)=>{
            throw new types_1.GoogleAuthError(util_1.constants.CREDENTIAL_ERROR_MESSAGE, e);
        });
        return tokenPromise;
    }
    getBaseUrl() {
        return `https://${this.location}-aiplatform.googleapis.com/${this.apiVersion}`;
    }
    getBaseResourePath() {
        return `projects/${this.project}/locations/${this.location}`;
    }
    async unaryApiCall(url, requestInit, httpMethod) {
        const token = await this.getHeaders();
        return this.apiCall(url.toString(), {
            ...requestInit,
            method: httpMethod,
            headers: token
        });
    }
    async apiCall(url, requestInit) {
        const response = await fetch(url, requestInit).catch((e)=>{
            throw new types_1.GoogleGenerativeAIError(`exception sending request to url: ${url} with requestInit: ${JSON.stringify(requestInit)}}`, e);
        });
        await throwErrorIfNotOK(response, url, requestInit).catch((e)=>{
            throw e;
        });
        try {
            return await response.json();
        } catch (e) {
            throw new types_1.GoogleGenerativeAIError(JSON.stringify(response), e);
        }
    }
    async getHeaders() {
        const token = await this.fetchToken();
        return new Headers({
            [AUTHORIZATION_HEADER]: `Bearer ${token}`,
            [CONTENT_TYPE_HEADER]: 'application/json',
            [USER_AGENT_HEADER]: util_1.constants.USER_AGENT
        });
    }
}
exports.ApiClient = ApiClient;
async function throwErrorIfNotOK(response, url, requestInit) {
    var _a;
    if (response === undefined) {
        throw new types_1.GoogleGenerativeAIError('response is undefined');
    }
    if (!response.ok) {
        const status = response.status;
        const statusText = response.statusText;
        let errorBody;
        if ((_a = response.headers.get('content-type')) === null || _a === void 0 ? void 0 : _a.includes('application/json')) {
            errorBody = await response.json();
        } else {
            errorBody = {
                error: {
                    message: `exception sending request to url: ${url} with requestInit: ${JSON.stringify(requestInit)}}`,
                    code: response.status,
                    status: response.statusText
                }
            };
        }
        const errorMessage = `got status: ${status} ${statusText}. ${JSON.stringify(errorBody)}`;
        if (status >= 400 && status < 500) {
            const error = new types_1.ClientError(errorMessage, new types_1.GoogleApiError(errorBody.error.message, errorBody.error.code, errorBody.error.status, errorBody.error.details));
            throw error;
        }
        throw new types_1.GoogleGenerativeAIError(errorMessage);
    }
} //# sourceMappingURL=api_client.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/resources/index.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ApiClient = exports.CachedContents = void 0;
var cached_contents_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/resources/cached_contents.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "CachedContents", {
    enumerable: true,
    get: function() {
        return cached_contents_1.CachedContents;
    }
});
var api_client_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/resources/shared/api_client.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "ApiClient", {
    enumerable: true,
    get: function() {
        return api_client_1.ApiClient;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/vertex_ai.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.VertexAI = void 0;
/* tslint:disable */ const google_auth_library_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/node_modules/google-auth-library/build/src/index.js [app-rsc] (ecmascript)");
const models_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/models/index.js [app-rsc] (ecmascript)");
const errors_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/errors.js [app-rsc] (ecmascript)");
const Resources = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/resources/index.js [app-rsc] (ecmascript)");
const cached_contents_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/resources/cached_contents.js [app-rsc] (ecmascript)");
/**
 * The `VertexAI` class is the base class for authenticating to Vertex AI.
 * To use Vertex AI's generative AI models, use the `getGenerativeModel` method.
 * To use generative AI features that are in Preview, use the `preview`
 * namespace.
 */ class VertexAI {
    /**
     * @constructor
     * @param init - assign authentication related information,
     *     including the project and location strings, to instantiate a Vertex AI
     * client.
     * @throws {IllegalArgumentError}
  
     */ constructor(init){
        const opts = validateGoogleAuthOptions(init.project, init.googleAuthOptions);
        this.location = resolveLocation(init.location);
        this.project = resolveProject(init.project);
        this.googleAuth = new google_auth_library_1.GoogleAuth(opts);
        this.apiEndpoint = init.apiEndpoint;
        this.preview = new VertexAIPreview(this.project, this.location, this.googleAuth, this.apiEndpoint);
    }
    /**
     * Gets the GenerativeModel class instance.
     *
     * This method creates a new instance of the `GenerativeModel` class with the
     * platform initialization parameters provided in {@link VertexInit} and model
     * initialization parameters provided in {@link ModelParams}. You can
     * optionally provide {@link RequestOptions} to override the default request
     * options.
     *
     * @example
     * ```
     * const project = 'your-cloud-project';
     * const location = 'us-central1';
     * const textModel =  'gemini-1.0-pro';
     * const visionModel = 'gemini-1.0-pro-vision';
     *
     * const vertexAI = new VertexAI({project: project, location: location});
     *
     * // Instantiate models
     * const generativeModel = vertexAI.getGenerativeModel({
     *   model: textModel,
     *   // The following parameters are optional
     *   // They can also be passed to individual content generation requests
     *   safetySettings: [{
     *                      category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
     *                      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
     *                     }],
     *   generationConfig: {maxOutputTokens: 256},
     * });
     *
     * const generativeVisionModel = vertexAI.getGenerativeModel({
     *   model: visionModel,
     * });
     *
     * const generativeModelPreview = vertexAI.preview.getGenerativeModel({
     *   model: textModel,
     * });
     * ```
     *
     * @param modelParams - {@link ModelParams} Parameters to
     *     specify the generative model.
     * @param requestOptions - {@link RequestOptions} Parameters to specify
     *     request options
     * @returns Instance of the GenerativeModel class.
     */ getGenerativeModel(modelParams, requestOptions) {
        const getGenerativeModelParams = {
            model: modelParams.model,
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            apiEndpoint: this.apiEndpoint,
            safetySettings: modelParams.safetySettings,
            generationConfig: modelParams.generationConfig,
            tools: modelParams.tools,
            toolConfig: modelParams.toolConfig,
            requestOptions: requestOptions,
            systemInstruction: modelParams.systemInstruction
        };
        return new models_1.GenerativeModel(getGenerativeModelParams);
    }
    getProject() {
        return this.project;
    }
    getLocation() {
        return this.location;
    }
}
exports.VertexAI = VertexAI;
/**
 * The preview namespace for VertexAI. Users invoke the `getGenerativeModel`
 * method to start using generative AI features that are in preview.
 */ class VertexAIPreview {
    /**
     * @constructor
     * @param project - The Google Cloud project to use for the request
     * @param location - location The Google Cloud project location to use for the
     *     request
     * @param googleAuth - The GoogleAuthen class instance from
     *     google-auth-library.
     *        Complete list of authentication options is documented in the
     * GoogleAuthOptions interface:
     *        https://github.com/googleapis/google-auth-library-nodejs/blob/main/src/auth/googleauth.ts
     * @param apiEndpoint - [apiEndpoint] The base Vertex AI endpoint to use for
     *     the request. If
     *        not provided, the default regionalized endpoint
     *        (i.e. us-central1-aiplatform.googleapis.com) will be used.
     */ constructor(project, location, googleAuth, apiEndpoint){
        this.project = project;
        this.location = location;
        this.googleAuth = googleAuth;
        this.apiEndpoint = apiEndpoint;
        this.apiClient = new Resources.ApiClient(this.project, this.location, 'v1beta1', this.googleAuth);
        this.cachedContents = new Resources.CachedContents(this.apiClient);
    }
    /**
     * @param modelParams - {@link ModelParams} Parameters to
     *     specify the generative model.
     * @returns Instance of the GenerativeModelPreview class.
     */ getGenerativeModel(modelParams, requestOptions) {
        const getGenerativeModelParams = {
            model: modelParams.model,
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            apiEndpoint: this.apiEndpoint,
            safetySettings: modelParams.safetySettings,
            generationConfig: modelParams.generationConfig,
            tools: modelParams.tools,
            toolConfig: modelParams.toolConfig,
            requestOptions: requestOptions,
            systemInstruction: modelParams.systemInstruction
        };
        return new models_1.GenerativeModelPreview(getGenerativeModelParams);
    }
    getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions) {
        if (!cachedContent.name) {
            throw new errors_1.ClientError('Cached content must contain a `name` field.');
        }
        if (!cachedContent.model) {
            throw new errors_1.ClientError('Cached content must contain a `model` field.');
        }
        validateCachedContentModel(cachedContent.model);
        /**
         * Not checking tools and toolConfig for now as it would require a deep
         * equality comparison and isn't likely to be a common case.
         */ const disallowedDuplicates = [
            'model',
            'systemInstruction'
        ];
        for (const key of disallowedDuplicates){
            if ((modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) && cachedContent[key] && (modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) !== cachedContent[key]) {
                if (key === 'model') {
                    const modelParamsComp = parseModelName(modelParams[key]);
                    const cachedContentComp = parseModelName(cachedContent[key]);
                    if (modelParamsComp === cachedContentComp) {
                        continue;
                    }
                }
                throw new errors_1.ClientError(`Different value for "${key}" specified in modelParams` + ` (${modelParams[key]}) and cachedContent (${cachedContent[key]})`);
            }
        }
        cachedContent.name = (0, cached_contents_1.inferFullResourceName)(this.project, this.location, cachedContent.name);
        const modelParamsFromCache = {
            model: cachedContent.model,
            project: this.project,
            location: this.location,
            googleAuth: this.googleAuth,
            apiEndpoint: this.apiEndpoint,
            safetySettings: modelParams === null || modelParams === void 0 ? void 0 : modelParams.safetySettings,
            generationConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.generationConfig,
            tools: cachedContent.tools,
            toolConfig: cachedContent.toolConfig,
            requestOptions: requestOptions,
            systemInstruction: cachedContent.systemInstruction,
            cachedContent
        };
        return new models_1.GenerativeModelPreview(modelParamsFromCache);
    }
}
function validateCachedContentModel(modelName) {
    if (modelName.startsWith('models/') || modelName.startsWith('projects/') && modelName.includes('/publishers/google/models/') || !modelName.includes('/')) {
        return;
    }
    throw new errors_1.ClientError(`Cached content model name must start with "models/" or match "projects/.*/publishers/google/models/.*" or is a model name listed at https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions. Received: ${modelName}`);
}
function parseModelName(modelName) {
    if (!modelName.includes('/')) {
        return modelName;
    }
    return modelName.split('/').pop();
}
function validateGoogleAuthOptions(project, googleAuthOptions) {
    let opts;
    const requiredScope = 'https://www.googleapis.com/auth/cloud-platform';
    if (!googleAuthOptions) {
        opts = {
            scopes: requiredScope
        };
        return opts;
    }
    if (googleAuthOptions.projectId && googleAuthOptions.projectId !== project) {
        throw new Error(`inconsistent project ID values. argument project got value ${project} but googleAuthOptions.projectId got value ${googleAuthOptions.projectId}`);
    }
    opts = googleAuthOptions;
    if (!opts.scopes) {
        opts.scopes = requiredScope;
        return opts;
    }
    if (typeof opts.scopes === 'string' && opts.scopes !== requiredScope || Array.isArray(opts.scopes) && opts.scopes.indexOf(requiredScope) < 0) {
        throw new errors_1.GoogleAuthError(`input GoogleAuthOptions.scopes ${opts.scopes} doesn't contain required scope ${requiredScope}, please include ${requiredScope} into GoogleAuthOptions.scopes or leave GoogleAuthOptions.scopes undefined`);
    }
    return opts;
}
function resolveProject(projectFromInput) {
    const projectNotFoundErrorMessage = 'Unable to infer your project.' + 'Please provide a project Id by one of the following:' + '\n- Passing a constructor argument by using new VertexAI({project: my-project})' + '\n- Setting project using `gcloud config set project my-project`';
    if (projectFromInput) {
        return projectFromInput;
    }
    const inferredProjectFromEnv = process.env['GOOGLE_CLOUD_PROJECT'];
    if (inferredProjectFromEnv) {
        return inferredProjectFromEnv;
    }
    throw new errors_1.IllegalArgumentError(projectNotFoundErrorMessage);
}
function resolveLocation(locationFromInput) {
    if (locationFromInput) {
        return locationFromInput;
    }
    const inferredLocation = process.env['GOOGLE_CLOUD_REGION'] || process.env['CLOUD_ML_REGION'];
    if (inferredLocation) {
        return inferredLocation;
    }
    return 'us-central1';
} //# sourceMappingURL=vertex_ai.js.map
}),
"[project]/node_modules/@google-cloud/vertexai/build/src/index.js [app-rsc] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/**
 * @license
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */ var __createBinding = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = {
            enumerable: true,
            get: function() {
                return m[k];
            }
        };
    }
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
});
var __exportStar = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__exportStar || function(m, exports1) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports1, p)) __createBinding(exports1, m, p);
};
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.VertexAI = void 0;
var vertex_ai_1 = __turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/vertex_ai.js [app-rsc] (ecmascript)");
Object.defineProperty(exports, "VertexAI", {
    enumerable: true,
    get: function() {
        return vertex_ai_1.VertexAI;
    }
});
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/types/index.js [app-rsc] (ecmascript)"), exports);
__exportStar(__turbopack_context__.r("[project]/node_modules/@google-cloud/vertexai/build/src/models/index.js [app-rsc] (ecmascript)"), exports); //# sourceMappingURL=index.js.map
}),
];

//# sourceMappingURL=node_modules_%40google-cloud_vertexai_build_src_140f0347._.js.map